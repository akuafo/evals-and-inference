Immediate fixes:
increase the final (key) thoughts section to include 4-6 items

Chuck new articles ideas:
- the risks of getting the evaluation wrong:  preventing misinformation, hallucinations, bias
- he'd be interested to learn more about the differences between llm evaluation and traditional software testing, what does it mean for software to be 'good enough to become customer facing' in traditional software development

new article ideas:  
- rag is overrated
- limitations of synthetic data

---

Ideas for my personal eval data sets:
- [ ] Intermittent fasting 
- [ ] Hemophilia A
- [ ] Parenting
- [ ] Tokachi region
- [ ] Japanese language learning
- [ ] Anki 
- [ ] Ai healthcare bias research 
- [ ] Shoulder injuries 
- [ ] Critical thinking

---

Platforms for multiple LLM hosting, can use for evaluation (from Devin coding demo):  Perplexity, Replicate, Together

---

Who is my audience:

Write a letter to a cto that tells them what they need to know about AI and evals.

Write a blog post that would meet the FAR.AI writing job description:  [https://far.ai/post/2022-04-senior-communications-specialist/](https://far.ai/post/2022-04-senior-communications-specialist/)

Twitter account posting on this topic:
[https://x.com/virattt?s=21](https://x.com/virattt?s=21)

---

obsidian setup:
* everything goes in the evals and inference folder
* unpublished content goes in 'rawnotes'
* published content goes in 'githubsite'

Process:
- To bookmark a new source, paste it into the 'New research topics.md' note
	- If time permits, take 5 minutes to write a description and create a new note in 'notes' with tags for knowledge graph
	- Move it to the githubsite folder so that it appears as a blog post
	- (If it fits a topic, add it to the note for that topic.  For example, a new post bout an evaluation library can be pasted into 'evaluation_companies_libraries.md')
- Daily posting:  pick 1 thing that seems interesting to others
- Daily learning:  pick 1 thing that that’s worth learning and spend 2-3 hours on it


---


Idea - Website generator for industry landscapes:  https://github.com/cncf/landscape2

Most important thing:  You need discipline to do good writing.  Block out time.  Have a goal.  Block distractions.  

Imagine someone in your head that you are writing to.  Establish that voice, tone, and writing level.

First, write a couple of articles for practice and resume building.  Second, find a few people to read and give feedback.  Third, focus on building an audience.

Write an 'intro to llm eval' blog post.  Include brief summaries of some popular evaluation software packages.  Later, create more detailed writeups with code samples.
    - [ ] Openai evals
    - [ ] https://www.braintrustdata.com
    - [ ] https://www.honeyhive.ai
    - [ ] https://www.patronus.ai
    - [ ] https://docs.promptlayer.com/features/evaluations/overview
    - [ ] LangSmith
    - [ ] humanloop

Idea based on Far.AI job description:
* 'Writing blog post summaries of papers, targeted at a technically knowledgeable (but not necessarily expert) audience (example).'
  * Example paper:  https://arxiv.org/abs/2211.00241
  * Blog post summary:  https://far.ai/post/2023-07-superhuman-go-ais/
* My first attempt can be a blog post to summarize this paper:  https://arxiv.org/pdf/2312.14302.pdf
* Submit my application:  https://far.ai/post/2022-04-senior-communications-specialist/

Writing idea: letters to a CTO

Audience:
CTO or CIO
Technical person whi is not an ML or LLM expert

Themes:
Solving pain of a CTO (Have you been asked to approve a new AI vendor?)
Explain how to do real world evaluations of AI systems, across different domains
Survey of what’s new and useful.  (5 new things in AI evaluations this week!)
Tell the story of my educational journey with ai evals

Don’t aim for the experts as my audience and don’t try to match the level of writing of a good academic paper, that’s too hard.

Idea:  Post once per day.  After 365 days, I can start mixing in re-posts from the previous year.

Idea:  Format can be 1. Here is something new, 2. Here is a line of code that I ran.

‘Learn in public with community’:  1) Pick 1 topic that I can summarize in 4 hours, 2) Identify 3 people that I can share it with privately, 3) Set internal and external deadlines.
  Set up 3 directories in Github:  private, shared, public
  Who do I know who is a) technical, b) has time to read about ai evaluations.
  Topic:  The new mirage benchmark.  GitHub repo.  Simple question and answer format.
  I need to consolidate all my notes and lists related to evaluations in 1 place:  GitHub repo.

My 'getting started' methodology for this repo is the following:
*  Start small and private
*  Set a daily cadence with calendar reminders for self-accountability
*  Set a schedule for measuring my progress and recognizing improvement
*  Find external accountability partners to stay on track
*  Distribute only to a private audience at first, then expand to the public sphere

Explore using generative AI to illustrate with video and animation, for example:  https://x.com/pfizer/status/1756803720250036644?s=20

When you start a new effort, don't even think about goals. Just focus on putting in the first 100 reps first.
Don't worry about weight loss, just work out 100x.
Don't worry about follower count, just publish 100x.
This helps you avoid giving up. Focus on the actions and the outcomes will come.
Peter Yang - Twitter
